The primary training dataset, accessible through this link (http://fenix.ur.edu.pl/mkepski/ds/uf.html) , comprises sequences of video data captured by cutting-edge motion capture and computer vision devices. These include Microsoft Kinect cameras and sensors such as the PS Move and x-IMU.The dataset consists of 70 detailed video sequences, with 30 dedicated to simulating falls and 40 for recording daily activities. This dataset provides essential data for training our model to accurately differentiate between these two types of events.
For the validation of our model, a secondary dataset was employed. This dataset, obtained from "Auvinet, C. Rougier, J. Meunier, A. St-Arnaud, and J. Rousseau" in January 2011, is known as the "Multiple Cameras Fall Data Set " (https://www.researchgate.net/publication/267693256_Multiple_cameras_fall_data_set)
is based on a multicamera system consisting of eight economical IP cameras strategically positioned to cover an entire room. The recorded video sequences reflect common challenges that can lead to segmentation errors, including high video compression, shadows, reflections, complex backgrounds, lighting variations, worn objects, and occlusions
